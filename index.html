<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Homepage - Susan Liang</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <script>
    tailwind.config = {
      theme: {
        extend: {
          fontFamily: {
            sans: ['Inter', 'sans-serif'],
          },
        }
      }
    }
  </script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VDYHMZZ07N"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-VDYHMZZ07N');
  </script>
  <style>
    /* Base badge styling */
    .badge {
      display: inline-flex;
      align-items: center;
      font-size: 0.75rem;         /* text-xs */
      font-weight: 600;           /* font-semibold */
      letter-spacing: 0.05em;     /* tracking-wide */
      padding: 0.25rem 0.75rem;   /* same as venue-badge */
      border-radius: 0.375rem;    /* same as venue-badge */
      margin-right: 0.5rem;
    }
  
    /* Specific badge types */
    .badge-award {
      background-color: #fef3c7; /* bg-yellow-100 */
      color: #92400e; /* text-yellow-800 */
    }
  
    .badge-oral {
      background-color: #ffedd5; /* bg-orange-100 */
      color: #9a3412; /* text-orange-800 */
    }
  
    .badge-hot {
      background-color: #fecaca; /* bg-red-100 */
      color: #991b1b; /* text-red-800 */
    }
  
    .link {
      color: #2563eb; /* text-blue-600 */
      transition: color 0.2s ease;
    }
  
    .link:hover {
      color: #f97316; /* hover:text-orange-500 */
    }
  
    /* Venue badge styling */
    .venue-badge {
      display: inline-flex;
      align-items: center;
      padding: 0.25rem 0.75rem;
      border-radius: 0.375rem;
      font-size: 0.75rem;
      font-weight: 600;
      letter-spacing: 0.05em;
      background: linear-gradient(135deg, #bfdbfe 0%, #93c5fd 100%);
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
      transition: all 0.2s ease;
    }
  
    .venue-badge:hover {
      transform: translateY(-1px);
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
  </style>
</head>

<body class="bg-gray-50 font-sans text-gray-800">

  <div class="container mx-auto max-w-5xl px-4 py-8 md:py-12">

    <header class="flex flex-col md:flex-row items-center mb-12 md:mb-16">
      <div class="md:w-2/3 md:pr-12 text-center md:text-left mb-8 md:mb-0">
        <h1 class="text-4xl md:text-5xl font-bold text-gray-900 mb-4">Susan Liang</h1>
        <p class="text-lg text-gray-700 mb-4 leading-relaxed">
          Hi, there! I am a third-year Ph.D. student in the Computer Science Department at the University of Rochester. My advisor is Prof. <a href="https://scholar.google.com/citations?user=54HfyDIAAAAJ&hl=en" class="link">Chenliang Xu</a>. Before joining Prof. Xu's lab, I got my bachelor degree of Computer Science at the University of Chinese Academy of Sciences. I was lucky to study and research under the supervision of Prof. <a href="https://scholar.google.com/citations?user=Vkzd7MIAAAAJ&hl=en" class="link">Shiguang Shan</a>. I joined Prof. Shan's group in 2020 and had worked there for one and a half years, enjoying an exciting research experience. I also worked closely with Prof. <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en" class="link">Ming-Hsuan Yang</a>.
        </p>
        <p class="text-lg text-gray-700 mb-4 leading-relaxed">
          My research interests lie in Computer Vision and Deep Learning, especially audio-visual learning, implicit neural fields, multi-modal learning, and trustworthy AI.
        </p>
        <p class="text-md text-gray-600 mb-6 italic bg-gray-100 p-3 rounded-lg border border-gray-200">
          Fun Fact: my Chinese name is Ê¢ÅËãèÂèÅ (Liang, Su, San), so Susan is just the *pinyin* of my Chinese name. Commonly, people think I am female when they see my English Name. There is an interesting clip about the pronunciation of Susan in the film <a href="https://youtu.be/4Ssu98-P6V4" class="link">Johnny English Reborn</a>. :D
        </p>
        <p class="text-lg text-red-600 font-semibold mb-6 p-3 bg-red-50 border border-red-200 rounded-lg">
          <span class="text-2xl mr-1">‚úâÔ∏è</span> I am actively looking for research internships for Summer 2025. Feel free to drop me a message if you are interested in.
        </p>
        <nav class="flex justify-center md:justify-start space-x-4">
          <a href="mailto:sliang22@ur.rochester.edu" class="link font-medium">Email</a>
          <span class="text-gray-400">/</span>
          <a href="documents/CV.pdf" class="link font-medium">CV</a>
          <span class="text-gray-400">/</span>
          <a href="https://github.com/liangsusan-git" class="link font-medium">Github</a>
          <span class="text-gray-400">/</span>
          <a href="https://scholar.google.com/citations?hl=en&user=x3HBE2gAAAAJ&view_op=list_works&gmla=AMpAcmQHFw83RicnhIX7_yE8CmD9-XXV_rbQaNWMU9RznV1aWk9TG2FnElAosWHE_JKSlXq6vmxkBd14rkniDqL0Xrdyi1Nc4tP1GQ" class="link font-medium">Google Scholar</a>
        </nav>
      </div>
      <div class="md:w-1/3 flex justify-center">
         <img src="image/profile_universial_studio.jpg" alt="Susan Liang profile picture" class="rounded-lg shadow-lg w-64 h-64 md:w-80 md:h-80 object-cover" onerror="this.onerror=null; this.src='https://placehold.co/320x320/e2e8f0/64748b?text=Susan+Liang';">
      </div>
    </header>

    <main>

      <section class="mb-12 md:mb-16">
        <h2 class="text-3xl font-semibold text-gray-900 mb-8 border-b border-gray-300 pb-3">Publications</h2>
        <div class="space-y-10">

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
            <img src="project/binauralflow/source/binauralflow.png" alt="BinauralFlow Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=BinauralFlow';">
            <div class="flex-1">
              <div><span class="venue-badge">ICML 2025</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models</h3>
              <p class="text-sm text-gray-600 mb-2">
                <b>Susan Liang</b>, Dejan Markovic, Israel D. Gebru, Steven Krenn, Todd Keebler, Jacob Sandakly, Frank Yu, Samuel Hassel, Chenliang Xu, Alexander Richard.
              </p>
              <p class="text-sm text-gray-500">Forty-second International Conference on Machine Learning, Jul. 2025.</p>
              <div class="mt-2 space-x-3">
                 <a href="project/binauralflow/" class="link">[Website]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/vidcomposition.png" alt="VIDCOMPOSITION Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=VidComposition';">
            <div class="flex-1">
              <div><span class="venue-badge">CVPR 2025</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">VIDCOMPOSITION: Can MLLMs Analyze Compositions in Compiled Videos?</h3>
              <p class="text-sm text-gray-600 mb-2">
                Yunlong Tang, Junjia Guo, Hang Hua, <b>Susan Liang</b>, Mingqian Feng, Xinyang Li, Rui Mao, Chao Huang, Jing Bi, Zeliang Zhang, Pooyan Fazli, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025, Jun. 2025.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/pdf/2411.10979" class="link">[Paper]</a>
                 <a href="https://yunlong10.github.io/VidComposition/" class="link">[Website]</a>
                 <a href="https://github.com/yunlong10/VidComposition" class="link">[Code]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/avattack.png" alt="AV Attack Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=AV+Attack';">
            <div class="flex-1">
              <div><span class="venue-badge">ICLR 2025</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Zeliang Zhang*, <b>Susan Liang*</b>, Daiki Shimada, Chenliang Xu. (* indicates equal contribution)
              </p>
              <p class="text-sm text-gray-500">The Thirteenth International Conference on Learning Representations, Apr. 2025.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2502.11858" class="link">[Paper]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/ai_animation.jpg" alt="AI Animation Survey Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=AI+Animation';">
            <div class="flex-1">
              <h3 class="text-lg font-semibold text-gray-800 mb-1">Generative AI for Cel-Animation: A Survey</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, <b>Susan Liang</b>, and Yizhi Song, Liu He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">arXiv preprint.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/pdf/2501.06250" class="link">[Paper]</a>
                 <a href="https://github.com/yunlong10/Awesome-AI4Animation" class="link">[Website]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/train_bias.png" alt="Train Bias Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=Train+Bias';">
            <div class="flex-1">
              <h3 class="text-lg font-semibold text-gray-800 mb-1">Will the Inclusion of Generated Data Amplify Bias Across Generations in Future Image Classification Models?</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Zeliang Zhang, Xin Liang, Mingqian Feng, <b>Susan Liang</b>, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">arXiv preprint.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/pdf/2410.10160" class="link">[Paper]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/scaling_concept.png" alt="Scaling Concept Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=Scaling+Concept';">
            <div class="flex-1">
              <h3 class="text-lg font-semibold text-gray-800 mb-1">Scaling Concept with Text-Guided Diffusion Models</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Chao Huang, <b>Susan Liang</b>, Yunlong Tang, Yapeng Tian, Anurag Kumar, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">arXiv preprint.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/pdf/2410.24151" class="link">[Paper]</a>
                 <a href="https://wikichao.github.io/ScalingConcept/" class="link">[Website]</a>
                 <a href="https://github.com/WikiChao/ScalingConcept" class="link">[Code]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/davis.png" alt="DAVIS Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=DAVIS';">
            <div class="flex-1">
              <div>
                <span class="venue-badge">ACCV 2024</span>
                <span class="badge badge-award">üèÜ Best Paper Honorable Mention</span>
              </div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">High-Quality Visually-Guided Sound Separation from Diverse Categories</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Chao Huang, <b>Susan Liang</b>, Yapeng Tian, Anurag Kumar, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">17th Asian Conference on Computer Vision, Dec. 2024.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2308.00122" class="link">[Paper]</a>
                 <a href="https://wikichao.github.io/data/projects/DAVIS/" class="link">[Website]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/avedit/source/teaser.svg" alt="AVEdit Teaser" class="w-64 h-auto object-contain rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 bg-white p-2 border mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=AVEdit';">
            <div class="flex-1">
              <div>
                <span class="venue-badge">ACCV 2024</span>
              </div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">Language-Guided Joint Audio-Visual Editing Via One-Shot Adaptation</h3>
              <p class="text-sm text-gray-600 mb-2">
                 <b>Susan Liang</b>, Chao Huang, Yapeng Tian, Anurag Kumar, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">17th Asian Conference on Computer Vision, Dec. 2024.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2410.07463" class="link">[Paper]</a>
                 <a href="project/avedit/" class="link">[Website]</a>
                 <a href="https://github.com/liangsusan-git/OAVE" class="link">[Dataset]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/l2t.png" alt="L2T Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=L2T';">
            <div class="flex-1">
              <div><span class="venue-badge">CVPR 2024</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">Learning to Transform Dynamically for Better Adversarial Transferability</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Rongyi Zhu*, Zeliang Zhang*, <b>Susan Liang</b>, Zhuo Liu, Chenliang Xu. (* indicates equal contribution)
              </p>
              <p class="text-sm text-gray-500">Conference on Computer Vision and Pattern Recognition, Jun. 2024.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2405.14077" class="link">[Paper]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/text_attack.png" alt="Text Attack Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=Text+Attack';">
            <div class="flex-1">
              <div><span class="venue-badge">EACL 2024</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">Random Smooth-based Certified Defense against Text Adversarial Attack</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Zeliang Zhang, Wei Yao, <b>Susan Liang</b>, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">Conference of the European Chapter of the Association for Computational Linguistics, Mar. 2024.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://aclanthology.org/2024.findings-eacl.83.pdf" class="link">[Paper]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/vid_llm.png" alt="Video LLM Survey Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=Video+LLM';">
            <div class="flex-1">
               <div>
                 <span class="venue-badge">TCSVT</span>
                 <span class="badge badge-hot">üî•üî•üî• HOT</span>
               </div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">Video Understanding with Large Language Models: A Survey</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Yunlong Tang*, Jing Bi*, Siting Xu*, Luchuan Song*, <b>Susan Liang</b>, Teng Wang, Daoan Zhang, Jie An, Jingyang Lin, Rongyi Zhu, Ali Vosoughi, Chao Huang, Zeliang Zhang, Feng Zheng, Jianguo Zhang, Ping Luo, Jiebo Luo, Chenliang Xu. (* indicates equal contribution)
              </p>
              <p class="text-sm text-gray-500">IEEE Transactions on Circuits and Systems for Video Technology.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2312.17432" class="link">[Paper]</a>
                 <a href="https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding" class="link">[Website]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/avnerf/source/teaser.svg" alt="AV-NeRF Teaser" class="w-64 h-auto object-contain rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 bg-white p-2 border mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=AV-NeRF';">
            <div class="flex-1">
              <div><span class="venue-badge">NeurIPS 2023</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</h3>
              <p class="text-sm text-gray-600 mb-2">
                 <b>Susan Liang</b>, Chao Huang, Yapeng Tian, Anurag Kumar, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">Conference on Neural Information Processing Systems, Dec. 2023.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2302.02088" class="link">[Paper]</a>
                 <a href="project/avnerf/" class="link">[Website]</a>
                 <a href="https://github.com/liangsusan-git/AV-NeRF" class="link">[Code/Dataset]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/nacf/source/model.png" alt="NACF Teaser" class="w-64 h-auto object-cover rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=NACF';">
            <div class="flex-1">
              <div><span class="venue-badge">ICCV Workshop 2023</span></div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">Neural Acoustic Context Field: Rendering Realistic Room Impulse Response With Neural Fields</h3>
              <p class="text-sm text-gray-600 mb-2">
                 <b>Susan Liang</b>, Chao Huang, Yapeng Tian, Anurag Kumar, Chenliang Xu.
              </p>
              <p class="text-sm text-gray-500">International Conference on Computer Vision Workshops, Oct. 2023.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2309.15977" class="link">[Paper]</a>
                 <a href="project/nacf/" class="link">[Website]</a>
              </div>
            </div>
          </article>

          <article class="flex flex-col md:flex-row md:items-center md:space-x-6">
             <img src="project/unicon.svg" alt="UniCon Teaser" class="w-64 h-auto object-contain rounded-lg shadow-md flex-shrink-0 mb-4 md:mb-0 bg-white p-2 border mx-auto md:mx-0" onerror="this.onerror=null; this.src='https://placehold.co/256x144/e0f2fe/0891b2?text=UniCon';">
            <div class="flex-1">
               <div>
                 <span class="venue-badge">ACM MM 2021</span>
                 <span class="badge badge-oral">Oral</span>
               </div>
              <h3 class="text-lg font-semibold text-gray-800 mt-1 mb-1">UniCon: Unified Context Network for Robust Active Speaker Detection</h3>
              <p class="text-sm text-gray-600 mb-2">
                 Yuanhang Zhang‚àó, <b>Susan Liang‚àó</b>, Shuang Yang, Xiao Liu, Zhongqin Wu, Shiguang Shan, Xilin Chen. (* indicates equal contribution)
              </p>
              <p class="text-sm text-gray-500">ACM International Conference on Multimedia, Oct. 2021.</p>
              <div class="mt-2 space-x-3">
                 <a href="https://arxiv.org/abs/2108.02607" class="link">[Paper]</a>
                 <a href="https://unicon-asd.github.io/" class="link">[Website]</a>
              </div>
            </div>
          </article>

        </div>
      </section>

      <section class="mb-12 md:mb-16">
        <h2 class="text-3xl font-semibold text-gray-900 mb-8 border-b border-gray-300 pb-3">Education</h2>
        <div class="space-y-6">
          <div class="flex items-start space-x-4">
             <img src="image/ur_logo.png" alt="University of Rochester Logo" class="h-16 w-16 object-contain flex-shrink-0" onerror="this.onerror=null; this.src='https://placehold.co/64x64/e2e8f0/64748b?text=UR';">
            <div>
              <h3 class="text-lg font-semibold text-gray-800">University of Rochester, NY, USA</h3>
              <p class="text-gray-600">Ph.D. Computer Science</p>
              <p class="text-sm text-gray-500">Sept. 2022 ‚Äì Present</p>
            </div>
          </div>
          <div class="flex items-start space-x-4">
             <img src="image/ucas_logo.jpeg" alt="University of Chinese Academy of Sciences Logo" class="h-16 w-16 object-contain flex-shrink-0" onerror="this.onerror=null; this.src='https://placehold.co/64x64/e2e8f0/64748b?text=UCAS';">
            <div>
              <h3 class="text-lg font-semibold text-gray-800">University of Chinese Academy of Sciences, Beijing, China</h3>
              <p class="text-gray-600">B.Eng. Computer Science</p>
              <p class="text-sm text-gray-500">Sept. 2018 ‚Äì Jul. 2022</p>
            </div>
          </div>
        </div>
      </section>

      <section class="mb-12 md:mb-16">
        <h2 class="text-3xl font-semibold text-gray-900 mb-8 border-b border-gray-300 pb-3">Research Experiences</h2>
        <div class="space-y-6">
          <div class="flex items-start space-x-4">
             <img src="image/meta_logo.png" alt="Meta Logo" class="h-16 w-16 object-contain flex-shrink-0" onerror="this.onerror=null; this.src='https://placehold.co/64x64/e2e8f0/64748b?text=Meta';">
            <div>
              <h3 class="text-lg font-semibold text-gray-800"><a href="https://about.meta.com/realitylabs/" class="link">Reality Labs Research, Meta</a>, PA, USA</h3>
              <p class="text-gray-600">Research Scientist Intern</p>
              <p class="text-sm text-gray-500">May 2024 ‚Äì Aug. 2024</p>
              <p class="text-sm text-gray-500">Advisors: Dr. <a href="https://scholar.google.com/citations?user=cyAYD3UAAAAJ&hl=en" class="link">Dejan Markovic</a>, Dr. <a href="https://scholar.google.it/citations?user=5RFgT84AAAAJ&hl=en" class="link">Israel D. Gebru</a>, and Dr. <a href="https://scholar.google.de/citations?user=73DTbNAAAAAJ&hl=de" class="link">Alexander Richard</a></p>
            </div>
          </div>
          <div class="flex items-start space-x-4">
             <img src="image/ucm_logo.png" alt="UC Merced Logo" class="h-16 w-16 object-contain flex-shrink-0" onerror="this.onerror=null; this.src='https://placehold.co/64x64/e2e8f0/64748b?text=UCM';">
            <div>
              <h3 class="text-lg font-semibold text-gray-800"><a href="http://vllab.ucmerced.edu/" class="link">Vision and Learning Lab, University of California - Merced</a>, CA, USA</h3>
              <p class="text-gray-600">Research Intern</p>
              <p class="text-sm text-gray-500">Sept. 2021 ‚Äì Mar. 2022</p>
              <p class="text-sm text-gray-500">Advisors: Prof. <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en" class="link">Ming-Hsuan Yang</a> and Dr. <a href="https://scholar.google.com/citations?user=Op_tr2IAAAAJ&hl=en" class="link">Taihong Xiao</a></p>
            </div>
          </div>
          <div class="flex items-start space-x-4">
             <img src="image/tsinghua_logo.png" alt="Tsinghua University Logo" class="h-16 w-16 object-contain flex-shrink-0" onerror="this.onerror=null; this.src='https://placehold.co/64x64/e2e8f0/64748b?text=Tsinghua';">
            <div>
              <h3 class="text-lg font-semibold text-gray-800"><a href="https://air.tsinghua.edu.cn/EN/" class="link">Institute for AI Industry Research, Tsinghua University</a>, Beijing, China</h3>
              <p class="text-gray-600">Research Intern</p>
              <p class="text-sm text-gray-500">Jun. 2021 ‚Äì Aug. 2021</p>
              <p class="text-sm text-gray-500">Advisors: Dr. Yizhi Wang and Dr. Hao Xu</p>
            </div>
          </div>
          <div class="flex items-start space-x-4">
             <img src="image/ucas_logo.jpeg" alt="UCAS Logo" class="h-16 w-16 object-contain flex-shrink-0" onerror="this.onerror=null; this.src='https://placehold.co/64x64/e2e8f0/64748b?text=UCAS';">
            <div>
              <h3 class="text-lg font-semibold text-gray-800"><a href="https://vipl.ict.ac.cn/en/" class="link">Visual Information Processing and Learning Group, Chinese Academy of Sciences</a>, Beijing, China</h3>
              <p class="text-gray-600">Research Assistant</p>
              <p class="text-sm text-gray-500">Feb. 2020 ‚Äì Apr. 2021</p>
              <p class="text-sm text-gray-500">Advisors: Prof. <a href="https://scholar.google.com/citations?user=Vkzd7MIAAAAJ&hl=en" class="link">Shiguang Shan</a> and Dr. <a href="https://scholar.google.com/citations?user=8wizL74AAAAJ&hl=en" class="link">Shuang Yang</a></p>
            </div>
          </div>
        </div>
      </section>

    </main>

    <footer class="mt-16 pt-8 border-t border-gray-300 text-center">
      <p class="text-sm text-gray-500">
        Website source from <a href="https://haidongz-usc.github.io/" class="link">Haidong Zhu</a>. Great thanks.
      </p>
      <p class="text-xs text-gray-400 mt-2">
        Modernized with Tailwind CSS.
      </p>
    </footer>

  </div>
</body>
</html>
